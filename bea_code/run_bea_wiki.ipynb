{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import digamma\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_le = LabelEncoder().fit(['B-LOC', 'B-ORG', 'B-PER', 'I-LOC', 'I-ORG', 'I-PER', 'O'])\n",
    "tag_le = LabelEncoder().fit(['LOC', 'ORG', 'PER', 'O'])\n",
    "\n",
    "num_classes = len(label_le.classes_)\n",
    "num_tags = len(tag_le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_entities(labels):\n",
    "    entities = []\n",
    "    pre_label = 'O'\n",
    "    pre_tag = 'O'\n",
    "    pre_sep = 0\n",
    "    for cur_idx, cur_label in enumerate(np.append(labels, 'O')):\n",
    "        cur_tag = cur_label.split('-')[-1]\n",
    "\n",
    "        if cur_tag != pre_tag or cur_label.startswith('B-'):\n",
    "            if pre_tag != 'O':\n",
    "                entities.append(((pre_sep, cur_idx), pre_tag))\n",
    "            pre_sep = cur_idx\n",
    "\n",
    "        pre_label = cur_label\n",
    "        pre_tag = cur_tag\n",
    "    return entities\n",
    "\n",
    "def get_f1(s1, s2):\n",
    "    return 2*len(s1 & s2) / (len(s1) + len(s2)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mv_infer(values):\n",
    "    num_classes = values.max() + 1\n",
    "    num_items, num_workers = values.shape\n",
    "    \n",
    "    all_items = np.arange(num_items)\n",
    "    z_ik = np.zeros((num_items, num_classes))\n",
    "\n",
    "    for j in range(num_workers):\n",
    "        z_ik[all_items, values[:, j]] += 1\n",
    "\n",
    "    return z_ik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Eq_log_pi_k_and_Eq_log_v_jkl(values, z_ik, alpha_k=1, beta_kl=1):\n",
    "    num_items, num_workers = values.shape\n",
    "    num_classes = z_ik.shape[1]\n",
    "    \n",
    "    alpha_k = alpha_k * np.ones(num_classes)\n",
    "    beta_kl = beta_kl * np.ones((num_classes, num_classes))\n",
    "    \n",
    "    Eq_log_pi_k = digamma(z_ik.sum(axis=0) + alpha_k) - digamma(num_items + alpha_k.sum())\n",
    "\n",
    "    n_jkl = np.zeros((num_workers, num_classes, num_classes)) + beta_kl\n",
    "    for j in range(num_workers):\n",
    "        for k in range(num_classes):\n",
    "            n_jkl[j, k, :] += np.bincount(values[:, j], z_ik[:, k], minlength=num_classes)\n",
    "    Eq_log_v_jkl = digamma(n_jkl) - digamma(n_jkl.sum(axis=-1, keepdims=True))\n",
    "\n",
    "    return Eq_log_pi_k, Eq_log_v_jkl\n",
    "\n",
    "def get_z_ik(values, Eq_log_v_jkl, Eq_log_pi_k=None, prior=False):\n",
    "    num_items, num_workers = values.shape\n",
    "    num_classes = Eq_log_v_jkl.shape[1]\n",
    "    \n",
    "    z_ik = np.zeros((num_items, num_classes))\n",
    "    if prior:\n",
    "        z_ik += Eq_log_pi_k\n",
    "\n",
    "    for j in range(num_workers):\n",
    "        z_ik += Eq_log_v_jkl[j, :, values[:, j]]\n",
    "    z_ik -= z_ik.max(axis=-1, keepdims=True)\n",
    "    z_ik = np.exp(z_ik)\n",
    "    z_ik /= z_ik.sum(axis=-1, keepdims=True)\n",
    "    \n",
    "    return z_ik\n",
    "\n",
    "def bea_infer(values, alpha_k=1, beta_kl=1, prior=True):\n",
    "    z_ik = mv_infer(values)\n",
    "    for iteration in range(500):\n",
    "        Eq_log_pi_k, Eq_log_v_jkl = get_Eq_log_pi_k_and_Eq_log_v_jkl(values, z_ik, alpha_k, beta_kl)\n",
    "        \n",
    "        last_z_ik = z_ik\n",
    "        z_ik = get_z_ik(values, Eq_log_v_jkl, Eq_log_pi_k, prior)\n",
    "        \n",
    "        if np.allclose(z_ik, last_z_ik, atol=1e-3):\n",
    "            break\n",
    "    return z_ik, Eq_log_v_jkl, Eq_log_pi_k, iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities_from_tok_results(z_ik):\n",
    "    return set(get_entities(label_le.inverse_transform(z_ik.argmax(axis=-1))))\n",
    "\n",
    "def get_entities_from_ent_results(z_ik, df_range):\n",
    "    df = pd.DataFrame(z_ik, index=df_range.index.set_names(['beg', 'end']), columns=pd.Series(tag_le.classes_, name='tag'))\n",
    "    df = df.stack().rename('prob').reset_index().sort_values('prob', ascending=False).drop_duplicates(['beg', 'end'])\n",
    "    num_items = df.end.max()\n",
    "    df = df[df['tag'] != 'O']\n",
    "    \n",
    "    pred_entities = set()\n",
    "    occupied = np.zeros(num_items)\n",
    "    for beg, end, tag, prob in df.values:\n",
    "        if occupied[beg:end].sum() == 0:\n",
    "            occupied[beg:end] = 1\n",
    "            pred_entities.add(((beg, end), tag))\n",
    "    return pred_entities\n",
    "\n",
    "def mv_tok(df_label):\n",
    "    z_ik = mv_infer(df_label.values)\n",
    "    return get_entities_from_tok_results(z_ik)\n",
    "\n",
    "def bea_tok(df_label, **kwargs):\n",
    "    z_ik, Eq_log_v_jkl, Eq_log_pi_k, iteration = bea_infer(df_label.values, **kwargs)\n",
    "    return get_entities_from_tok_results(z_ik), Eq_log_v_jkl, Eq_log_pi_k, iteration\n",
    "\n",
    "def mv_ent(df_range):\n",
    "    z_ik = mv_infer(df_range.values)\n",
    "    return get_entities_from_ent_results(z_ik, df_range)\n",
    "\n",
    "def bea_ent(df_range, **kwargs):\n",
    "    z_ik, Eq_log_v_jkl, Eq_log_pi_k, iteration = bea_infer(df_range.values, **kwargs)\n",
    "    return get_entities_from_ent_results(z_ik, df_range), Eq_log_v_jkl, Eq_log_pi_k, iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_range(df_label):\n",
    "    return pd.DataFrame({source: dict(get_entities(label_le.inverse_transform(df_label[source].values)))\n",
    "                         for source in df_label.columns}).fillna('O').apply(tag_le.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_recall(Eq_log_v_jkl, sources):\n",
    "    v_jkl = np.exp(Eq_log_v_jkl)\n",
    "    v_jkl /= v_jkl.sum(axis=-1, keepdims=True)\n",
    "\n",
    "    df_recall = pd.DataFrame(v_jkl[:, np.arange(num_tags), np.arange(num_tags)], columns=tag_le.classes_)\n",
    "    df_recall['source'] = sources\n",
    "    df_recall['Avg3'] = df_recall[['LOC', 'ORG', 'PER']].mean(axis=1)\n",
    "    \n",
    "    return df_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data_wiki/'\n",
    "\n",
    "languages = ['af']\n",
    "# languages = ['af', 'ar', 'bg', 'bn', 'bs', 'ca', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fa', 'fi', 'fr', 'he', 'hi',\n",
    "#              'hr', 'hu', 'id', 'it', 'lt', 'lv', 'mk', 'ms', 'nl', 'no', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sq', 'sv',\n",
    "#              'ta', 'tl', 'tr', 'uk', 'vi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised setting (use the first 100 sentences in dev as gold data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for language in languages:\n",
    "    dataset = language + '_test'\n",
    "    df_label = pd.read_csv(data_path + dataset + '/label.csv')\n",
    "    df_truth = pd.read_csv(data_path + dataset + '/truth.csv')\n",
    "    true_entities = set(get_entities(df_truth.truth.values))\n",
    "        \n",
    "    dataset_dev = language + '_dev'\n",
    "    df_label_dev = pd.read_csv(data_path + dataset_dev + '/label.csv')\n",
    "    df_truth_dev = pd.read_csv(data_path + dataset_dev + '/truth.csv')\n",
    "    \n",
    "    df_label_gold = df_label_dev[df_truth_dev.sent_idx<100].copy()\n",
    "    df_truth_gold = df_truth_dev[df_truth_dev.sent_idx<100]\n",
    "    \n",
    "    # get Eq_log_pi_k and Eq_log_v_jkl from gold sentences (ent level)\n",
    "    df_label_gold['#truth'] = label_le.transform(df_truth_gold.truth)\n",
    "    df_range_gold = get_df_range(df_label_gold)\n",
    "\n",
    "    truth_gold = df_range_gold['#truth']\n",
    "    df_range_gold.drop('#truth', axis=1, inplace=True)\n",
    "\n",
    "    one_hot_truth_gold = np.zeros((df_range_gold.shape[0], num_tags))\n",
    "    one_hot_truth_gold[np.arange(df_range_gold.shape[0]), truth_gold] = 1\n",
    "\n",
    "    # ent level Eq_log_pi_k and Eq_log_v_jkl\n",
    "    Eq_log_pi_k, Eq_log_v_jkl = get_Eq_log_pi_k_and_Eq_log_v_jkl(df_range_gold.values, one_hot_truth_gold)\n",
    "    \n",
    "    # rank\n",
    "    df_recall = get_df_recall(Eq_log_v_jkl, df_range_gold.columns).sort_values('Avg3', ascending=False)\n",
    "    \n",
    "    for topK in [3, 10, 20]:\n",
    "        # mv-tok-sup\n",
    "        pred_entities = mv_tok(df_label[df_recall.source[:topK]])\n",
    "        records.append((dataset, 'MV-tok-sup-t%d'%topK, get_f1(true_entities, pred_entities)))\n",
    "\n",
    "        # mv-ent-sup\n",
    "        df_range = get_df_range(df_label[df_recall.source[:topK]])\n",
    "        pred_entities = mv_ent(df_range)\n",
    "        records.append((dataset, 'MV-ent-sup-t%d'%topK, get_f1(true_entities, pred_entities)))\n",
    "\n",
    "        # bcc-ent-sup\n",
    "        df_range = get_df_range(df_label[df_recall.source[:topK]])\n",
    "        z_ik = get_z_ik(df_range.values, Eq_log_v_jkl[df_recall.index[:topK]], Eq_log_pi_k, prior=True)\n",
    "\n",
    "        pred_entities = get_entities_from_ent_results(z_ik, df_range)\n",
    "        records.append((dataset, 'BEA-ent-sup-t%d'%topK, get_f1(true_entities, pred_entities)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_v, b_v = 1, 1\n",
    "beta_kl = np.eye(num_classes) * (a_v-b_v) + b_v\n",
    "beta_kl_tag = np.eye(num_tags) * (a_v-b_v) + b_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# records = [] # we already have 'records' of supervised setting\n",
    "for language in languages:\n",
    "    dataset = language + '_test'\n",
    "    df_label = pd.read_csv(data_path + dataset + '/label.csv')\n",
    "    df_truth = pd.read_csv(data_path + dataset + '/truth.csv')\n",
    "    \n",
    "    true_entities = set(get_entities(df_truth.truth.values))\n",
    "    for source in df_label.columns:\n",
    "        pred_entities = set(get_entities(label_le.inverse_transform(df_label[source].values)))\n",
    "        f1 = get_f1(true_entities, pred_entities)\n",
    "        records.append((dataset, source, f1))\n",
    "        \n",
    "    # token level\n",
    "    pred_entities = mv_tok(df_label)\n",
    "    records.append((dataset, 'MV-tok', get_f1(true_entities, pred_entities)))\n",
    "    \n",
    "    pred_entities = bea_tok(df_label, beta_kl=beta_kl, prior=True)[0]\n",
    "    records.append((dataset, 'BEA-tok', get_f1(true_entities, pred_entities)))\n",
    "    \n",
    "    # entity level\n",
    "    df_range = get_df_range(df_label)\n",
    "    \n",
    "    pred_entities = mv_ent(df_range)\n",
    "    records.append((dataset, 'MV-ent', get_f1(true_entities, pred_entities)))\n",
    "    \n",
    "    pred_entities, Eq_log_v_jkl = bea_ent(df_range, beta_kl=beta_kl_tag, prior=True)[:2]\n",
    "    records.append((dataset, 'BEA-ent', get_f1(true_entities, pred_entities)))\n",
    "    \n",
    "    # spammer removel\n",
    "    # round 1, pick top 20\n",
    "    df_recall = get_df_recall(Eq_log_v_jkl, df_range.columns).sort_values('Avg3', ascending=False)\n",
    "    \n",
    "    df_range = get_df_range(df_label[df_recall.source[:20]])\n",
    "    pred_entities, Eq_log_v_jkl = bea_ent(df_range, beta_kl=beta_kl_tag, prior=True)[:2]\n",
    "    records.append((dataset, 'BEA-ent-x1-t20', get_f1(true_entities, pred_entities)))\n",
    "    \n",
    "    # round 2, pick top 10\n",
    "    df_recall = get_df_recall(Eq_log_v_jkl, df_range.columns).sort_values('Avg3', ascending=False)\n",
    "    \n",
    "    df_range = get_df_range(df_label[df_recall.source[:10]])\n",
    "    pred_entities, Eq_log_v_jkl = bea_ent(df_range, beta_kl=beta_kl_tag, prior=True)[:2]\n",
    "    records.append((dataset, 'BEA-ent-x2-t10', get_f1(true_entities, pred_entities)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame.from_records(records, columns=['dataset', 'method', 'f1'])\n",
    "df_pivot = df_res.pivot(index='dataset', columns='method', values='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BEA-ent-sup-t3</th>\n",
       "      <td>81.365005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MV-ent-sup-t3</th>\n",
       "      <td>81.206030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MV-ent-sup-t10</th>\n",
       "      <td>80.273973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEA-ent-sup-t10</th>\n",
       "      <td>80.252240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MV-tok-sup-t3</th>\n",
       "      <td>79.803601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl</th>\n",
       "      <td>79.786880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEA-ent-x1-t20</th>\n",
       "      <td>79.609033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEA-ent-sup-t20</th>\n",
       "      <td>79.494008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEA-ent-x2-t10</th>\n",
       "      <td>79.439891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MV-ent-sup-t20</th>\n",
       "      <td>79.257183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEA-ent</th>\n",
       "      <td>79.256555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MV-tok-sup-t10</th>\n",
       "      <td>78.891821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MV-tok-sup-t20</th>\n",
       "      <td>78.445699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>75.408764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MV-tok</th>\n",
       "      <td>75.231879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>da</th>\n",
       "      <td>74.818721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MV-ent</th>\n",
       "      <td>74.796117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>73.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEA-tok</th>\n",
       "      <td>73.306275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fi</th>\n",
       "      <td>73.257373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs</th>\n",
       "      <td>72.775389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pl</th>\n",
       "      <td>72.393488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bs</th>\n",
       "      <td>69.881202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hu</th>\n",
       "      <td>69.825601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hr</th>\n",
       "      <td>69.809359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>69.405478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>68.829431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>68.455497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>68.337731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sk</th>\n",
       "      <td>67.776298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ro</th>\n",
       "      <td>67.619380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>66.644045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lt</th>\n",
       "      <td>65.205479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sl</th>\n",
       "      <td>64.223989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>62.951054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es</th>\n",
       "      <td>61.874793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ms</th>\n",
       "      <td>61.395669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>58.838878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lv</th>\n",
       "      <td>58.110883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv</th>\n",
       "      <td>58.006042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>56.422171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sq</th>\n",
       "      <td>55.174687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vi</th>\n",
       "      <td>52.140078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el</th>\n",
       "      <td>42.013311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tl</th>\n",
       "      <td>39.454191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uk</th>\n",
       "      <td>36.715789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mk</th>\n",
       "      <td>36.462797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ru</th>\n",
       "      <td>34.528552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bg</th>\n",
       "      <td>31.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>25.719424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ar</th>\n",
       "      <td>12.232779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hi</th>\n",
       "      <td>7.911576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fa</th>\n",
       "      <td>6.026786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ta</th>\n",
       "      <td>0.894569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bn</th>\n",
       "      <td>0.390371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mean\n",
       "BEA-ent-sup-t3   81.365005\n",
       "MV-ent-sup-t3    81.206030\n",
       "MV-ent-sup-t10   80.273973\n",
       "BEA-ent-sup-t10  80.252240\n",
       "MV-tok-sup-t3    79.803601\n",
       "nl               79.786880\n",
       "BEA-ent-x1-t20   79.609033\n",
       "BEA-ent-sup-t20  79.494008\n",
       "BEA-ent-x2-t10   79.439891\n",
       "MV-ent-sup-t20   79.257183\n",
       "BEA-ent          79.256555\n",
       "MV-tok-sup-t10   78.891821\n",
       "MV-tok-sup-t20   78.445699\n",
       "it               75.408764\n",
       "MV-tok           75.231879\n",
       "da               74.818721\n",
       "MV-ent           74.796117\n",
       "no               73.733333\n",
       "BEA-tok          73.306275\n",
       "fi               73.257373\n",
       "cs               72.775389\n",
       "pl               72.393488\n",
       "bs               69.881202\n",
       "hu               69.825601\n",
       "hr               69.809359\n",
       "id               69.405478\n",
       "et               68.829431\n",
       "fr               68.455497\n",
       "en               68.337731\n",
       "sk               67.776298\n",
       "ro               67.619380\n",
       "de               66.644045\n",
       "lt               65.205479\n",
       "sl               64.223989\n",
       "tr               62.951054\n",
       "es               61.874793\n",
       "ms               61.395669\n",
       "ca               58.838878\n",
       "lv               58.110883\n",
       "sv               58.006042\n",
       "pt               56.422171\n",
       "sq               55.174687\n",
       "vi               52.140078\n",
       "el               42.013311\n",
       "tl               39.454191\n",
       "uk               36.715789\n",
       "mk               36.462797\n",
       "ru               34.528552\n",
       "bg               31.538462\n",
       "he               25.719424\n",
       "ar               12.232779\n",
       "hi                7.911576\n",
       "fa                6.026786\n",
       "ta                0.894569\n",
       "bn                0.390371"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot.agg(['mean']).T.sort_values('mean', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
